{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29641,"status":"ok","timestamp":1727333513261,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"4Af6K3XeQBiu","outputId":"20b1ab78-1d80-400b-fdd8-215f5f1b60b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183582,"status":"ok","timestamp":1727334332306,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"IQ717IDwPEWC","outputId":"7b83c9a6-c16c-42e7-b99b-a4b021975df3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/kermany2018\n","Dataset downloaded successfully!\n"]}],"source":["import os\n","import json\n","import shutil\n","\n","# Path to your kaggle.json file\n","kaggle_json_path = '/content/drive/Othercomputers/My laptop/Current_Project_Code_Files/kaggle.json'\n","\n","# Kaggle config directory\n","kaggle_config_dir = '/root/.config/kaggle'\n","\n","# Create Kaggle config directory if it doesn't exist\n","os.makedirs(kaggle_config_dir, exist_ok=True)\n","\n","# Copy the kaggle.json file to the Kaggle config directory\n","shutil.copy(kaggle_json_path, os.path.join(kaggle_config_dir, 'kaggle.json'))\n","\n","# Set proper permissions for the kaggle.json file\n","os.chmod(os.path.join(kaggle_config_dir, 'kaggle.json'), 600)\n","\n","# Now we can import and use the Kaggle API\n","import kaggle\n","\n","# Download and unzip the dataset\n","kaggle.api.dataset_download_files('paultimothymooney/kermany2018', path='.', unzip=True)\n","\n","print(\"Dataset downloaded successfully!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11835,"status":"ok","timestamp":1727334390831,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"Dzo-zxtIeJ46","outputId":"e05eb313-0ffa-42c7-bb55-748cfba4ed6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 0s 0us/step\n"]}],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","\n","# Load the pre-trained ResNet50 model without the top layers\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the base model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add new layers\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dense(128, activation='relu')(x)\n","outputs = Dense(4, activation='softmax')(x)\n","\n","# Create the final model\n","model = Model(inputs=base_model.input, outputs=outputs)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2647,"status":"ok","timestamp":1727334400090,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"NQdylKbexiVi","outputId":"8a91d705-ce2f-433b-94a9-7e83f61e5226"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting imbalanced-learn\n","  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n","Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/258.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/258.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: imbalanced-learn\n","Successfully installed imbalanced-learn-0.12.3\n"]}],"source":["!pip install imbalanced-learn"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28894,"status":"ok","timestamp":1727334493410,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"kJ2AHf7H6vM_","outputId":"a6251efb-dc8e-4501-9b69-1280c0db100c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total images loaded: 8000\n","Number of classes: 4\n","  NORMAL: 2000 images\n","  CNV: 2000 images\n","  DME: 2000 images\n","  DRUSEN: 2000 images\n"]}],"source":["\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils import shuffle\n","\n","def load_image_data(data_dir, class_names, img_size=(224, 224), max_images_per_class=None):\n","    images = []\n","    labels = []\n","    for class_index, class_name in enumerate(class_names):\n","        class_dir = os.path.join(data_dir, class_name)\n","        image_count = 0\n","        for img_name in os.listdir(class_dir):\n","            if max_images_per_class and image_count >= max_images_per_class:\n","                break\n","            img_path = os.path.join(class_dir, img_name)\n","            # Load and resize the image\n","            img = load_img(img_path, target_size=img_size)\n","            # Convert the image to a numerical array\n","            img_array = img_to_array(img)\n","            img_array = img_array / 255.0\n","            images.append(img_array)\n","            labels.append(class_index)\n","            image_count += 1\n","    return np.array(images), np.array(labels)\n","\n","\n","data_dir = '/content/OCT2017 /train'\n","data_dir2 = '/content/OCT2017 /test'\n","class_names = ['NORMAL', 'CNV', 'DME', 'DRUSEN']\n","\n","\n","training_imgs, img_labels = load_image_data(data_dir, class_names, max_images_per_class=2000)\n","val_imgs, v_img_labels = load_image_data(data_dir2, class_names, max_images_per_class=40)\n","\n","# Convert labels to categorical (one-hot encoding)\n","y_train = to_categorical(img_labels, num_classes=4)\n","y_val = to_categorical(v_img_labels, num_classes=4)\n","\n","y_train_int = np.argmax(y_train, axis=1)\n","\n","# Reshape the image data to 2D\n","n_samples, height, width, channels = training_imgs.shape\n","X_reshaped = training_imgs.reshape((n_samples, -1))\n","\n","# Apply oversampling\n","oversample = RandomOverSampler(sampling_strategy='auto', random_state=42)\n","X_resampled, y_resampled = oversample.fit_resample(X_reshaped, y_train_int)\n","\n","# Reshape the oversampled data back to image format\n","X_resampled = X_resampled.reshape((-1, height, width, channels))\n","\n","# Convert the labels back to one-hot encoding\n","y_resampled = to_categorical(y_resampled, num_classes=4)\n","\n","# Shuffle the oversampled data\n","X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n","\n","\n","# Print some information about the loaded dataset\n","print(f\"Total images loaded: {len(training_imgs)}\")\n","print(f\"Number of classes: {len(class_names)}\")\n","for i, class_name in enumerate(class_names):\n","    class_count = np.sum(img_labels == i)\n","    print(f\"  {class_name}: {class_count} images\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1726990417098,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"RI1DfNmECVDr","outputId":"28554ab1-05b3-4484-fab8-cf883ff27adc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total images in each class:\n","  NORMAL: 26315 images\n","  CNV: 37205 images\n","  DME: 11348 images\n","  DRUSEN: 8616 images\n"]}],"source":["class_counts = {}\n","\n","for class_name in class_names:\n","    class_dir = os.path.join(data_dir, class_name)\n","    image_count = len([name for name in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, name))])\n","    class_counts[class_name] = image_count\n","\n","print(\"Total images in each class:\")\n","for class_name, count in class_counts.items():\n","    print(f\"  {class_name}: {count} images\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165944,"status":"ok","timestamp":1727341639948,"user":{"displayName":"Abdul Wahab Basalirwa","userId":"17965559081876819405"},"user_tz":-240},"id":"B_QHR5vB9Hcb","outputId":"1d13276c-9f6c-407c-d8f8-ccf36fb85fd8"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/80\n","65/65 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.5673"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["65/65 [==============================] - 136s 2s/step - loss: 1.0089 - accuracy: 0.5673 - val_loss: 0.9063 - val_accuracy: 0.6000\n","Epoch 2/80\n","65/65 [==============================] - 136s 2s/step - loss: 0.9913 - accuracy: 0.5741 - val_loss: 0.8389 - val_accuracy: 0.6812\n","Epoch 3/80\n","65/65 [==============================] - 132s 2s/step - loss: 0.9818 - accuracy: 0.5831 - val_loss: 0.8385 - val_accuracy: 0.6687\n","Epoch 4/80\n","65/65 [==============================] - 135s 2s/step - loss: 1.0051 - accuracy: 0.5664 - val_loss: 0.9308 - val_accuracy: 0.6187\n","Epoch 5/80\n","65/65 [==============================] - 139s 2s/step - loss: 1.0409 - accuracy: 0.5421 - val_loss: 0.8503 - val_accuracy: 0.6687\n","Epoch 6/80\n","65/65 [==============================] - 139s 2s/step - loss: 1.0270 - accuracy: 0.5491 - val_loss: 0.8024 - val_accuracy: 0.6812\n","Epoch 7/80\n","65/65 [==============================] - 140s 2s/step - loss: 1.0152 - accuracy: 0.5567 - val_loss: 0.7996 - val_accuracy: 0.7125\n","Epoch 8/80\n","65/65 [==============================] - 140s 2s/step - loss: 0.9759 - accuracy: 0.5869 - val_loss: 0.8059 - val_accuracy: 0.6562\n","Epoch 9/80\n","65/65 [==============================] - 144s 2s/step - loss: 0.9782 - accuracy: 0.5821 - val_loss: 0.8571 - val_accuracy: 0.6375\n","Epoch 10/80\n","65/65 [==============================] - 143s 2s/step - loss: 0.9772 - accuracy: 0.5750 - val_loss: 0.8014 - val_accuracy: 0.6812\n","Epoch 11/80\n","65/65 [==============================] - 142s 2s/step - loss: 0.9703 - accuracy: 0.5844 - val_loss: 0.8131 - val_accuracy: 0.6500\n","Epoch 12/80\n","65/65 [==============================] - 142s 2s/step - loss: 0.9744 - accuracy: 0.5820 - val_loss: 0.8203 - val_accuracy: 0.6812\n","5/5 [==============================] - 3s 573ms/step\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      NORMAL       0.85      0.82      0.84        40\n","         CNV       0.68      0.68      0.68        40\n","         DME       0.57      0.65      0.60        40\n","      DRUSEN       0.80      0.70      0.75        40\n","\n","    accuracy                           0.71       160\n","   macro avg       0.72      0.71      0.72       160\n","weighted avg       0.72      0.71      0.72       160\n","\n"]}],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.metrics import classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","\n","# Compute class weights\n","class_weights = compute_class_weight('balanced', classes=np.unique(img_labels), y=img_labels)\n","class_weight_dict = dict(enumerate(class_weights))\n","\n","# Set up callbacks\n","checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","''' Train the model using numpy arrays directly\n","history = model.fit(\n","    training_imgs,\n","    y_train,\n","    validation_data=(val_imgs, y_val),\n","    epochs=5,\n","    batch_size=124,\n","    callbacks=[checkpoint, early_stop],\n","    class_weight=class_weight_dict\n",")'''\n","\n","# Train the model with the resampled data\n","history = model.fit(\n","    X_resampled,\n","    y_resampled,\n","    validation_data=(val_imgs, y_val),\n","    epochs=80,\n","    batch_size=124,\n","    callbacks=[checkpoint, early_stop],\n","    class_weight=class_weight_dict\n",")\n","# Generate predictions\n","y_pred = model.predict(val_imgs)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(y_val, axis=1)\n","\n","# Generate and print the classification report\n","class_names = ['NORMAL', 'CNV', 'DME', 'DRUSEN']\n","report = classification_report(y_true, y_pred_classes, target_names=class_names)\n","print(\"\\nClassification Report:\")\n","print(report)"]},{"cell_type":"code","source":["\n"],"metadata":{"id":"HqQJWTcwVRSh"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}